{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando librearias\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from Resources.mlTracker import *\n",
    "from Python.Style.styles import  *\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desactivando wrnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/training_shuffled.parquet\")\n",
    "training_us = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/undersampled_shuffled.parquet\")\n",
    "testing1 = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/testing1.parquet\")\n",
    "testing2 = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/testing2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To delete columns\n",
    "total_columns = training.columns\n",
    "tdc = ['serialNumber','serialNumber_neighbor','fixed_path','FE-Comments','Conjunto','PSNumber']\n",
    "training_cols = list(filter(lambda x: x not in tdc, total_columns))\n",
    "#Seleccionando columnas\n",
    "training = training[training_cols]\n",
    "training_us = training_us[training_cols]\n",
    "testing1 = testing1[training_cols]\n",
    "testing2 = testing2[training_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando etiquetas\n",
    "#Training\n",
    "y = training['Communicating']\n",
    "X = training.drop('Communicating', axis=1)\n",
    "#Training undersampled\n",
    "y_us = training_us['Communicating']\n",
    "X_us = training_us.drop('Communicating', axis=1)\n",
    "#Test1\n",
    "y_testing_1 = testing1['Communicating']\n",
    "X_testing_1 = testing1.drop('Communicating', axis=1)\n",
    "#Test2\n",
    "y_testing_2 = testing2['Communicating']\n",
    "X_testing_2 = testing2.drop('Communicating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seteando experimento\n",
    "experiment_name = \"ML\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros de búsqueda\n",
    "param_grid = {\n",
    "    'n_neighbors': [1,2,3] + list(range(4,20,2)),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "#Métricas de interés\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo y GridSearchCV\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = RandomizedSearchCV(\n",
    "                            estimator= knn,\n",
    "                            param_distributions= param_grid,\n",
    "                            n_iter= 10,\n",
    "                            cv= 3,\n",
    "                            scoring= scoring,\n",
    "                            refit= 'F1',\n",
    "                            return_train_score= False,\n",
    "                            n_jobs= -1,\n",
    "                            verbose= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando hiperparámetros para KNN con df Training completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ....................n_neighbors=1, weights=distance; total time=44.4min\n",
      "[CV] END ....................n_neighbors=1, weights=distance; total time=44.5min\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=44.5min\n",
      "[CV] END ....................n_neighbors=1, weights=distance; total time=44.5min\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=44.5min\n",
      "[CV] END ....................n_neighbors=4, weights=distance; total time=44.5min\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=44.5min\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=44.6min\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=15.7min\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=15.7min\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=15.7min\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=15.8min\n",
      "[CV] END ...................n_neighbors=14, weights=distance; total time=15.6min\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=15.7min\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=15.8min\n",
      "[CV] END .....................n_neighbors=4, weights=uniform; total time=21.7min\n",
      "[CV] END ...................n_neighbors=14, weights=distance; total time=17.5min\n",
      "[CV] END ...................n_neighbors=14, weights=distance; total time=17.5min\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=17.6min\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=17.6min\n",
      "[CV] END ....................n_neighbors=8, weights=distance; total time=17.6min\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=17.8min\n",
      "[CV] END ....................n_neighbors=8, weights=distance; total time=22.6min\n",
      "[CV] END ....................n_neighbors=8, weights=distance; total time=18.8min\n",
      "[CV] END .....................n_neighbors=2, weights=uniform; total time=13.8min\n",
      "[CV] END .....................n_neighbors=2, weights=uniform; total time=13.9min\n",
      "[CV] END ...................n_neighbors=12, weights=distance; total time=13.7min\n",
      "[CV] END ...................n_neighbors=12, weights=distance; total time=13.7min\n",
      "[CV] END .....................n_neighbors=2, weights=uniform; total time=15.8min\n",
      "[CV] END ...................n_neighbors=12, weights=distance; total time=15.6min\n"
     ]
    }
   ],
   "source": [
    "#Ajustando para training\n",
    "with mlflow.start_run(run_name=\"KNN-Training\"):\n",
    "    knn1 = grid_search.fit(X, y)\n",
    "    #Mejor modelo\n",
    "    best_model = knn1.best_estimator_\n",
    "    #Guardando resultados\n",
    "    mlflow.log_params(knn1.best_params_)\n",
    "    mlflow.log_metrics({\"best_score\":knn1.best_score_})\n",
    "    mlflow.sklearn.log_model(best_model,\"best_model\")\n",
    "    mlflow.sklearn.log_model(knn1, \"RandomizedSearchCV\")\n",
    "    #Guardando diccionario de resultados\n",
    "    results = knn1.cv_results_\n",
    "    results = pd.DataFrame(results)\n",
    "    with tempfile.NamedTemporaryFile(mode = \"w+\", suffix = \".parquet\", delete= False) as temp:\n",
    "        results.to_parquet(temp.name)\n",
    "        mlflow.log_artifact(temp.name,\"results/results.parquet\")\n",
    "        temp_path = temp.name\n",
    "    #Almacenando métricas con conjunto de datos\n",
    "    f1_test1 = f1_score(y_testing_1, knn1.predict(X_testing_1), average='macro')\n",
    "    f1_test2 = f1_score(y_testing_2, knn1.predict(X_testing_2), average='macro')\n",
    "    accuracy_test1 = accuracy_score(y_testing_1, knn1.predict(X_testing_1))\n",
    "    accuracy_test2 = accuracy_score(y_testing_2, knn1.predict(X_testing_2))\n",
    "    mlflow.log_metrics({\"f1_test1\":f1_test1, \"f1_test2\":f1_test2, \"accuracy_test1\":accuracy_test1, \"accuracy_test2\":accuracy_test2})\n",
    "    os.remove(temp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultaods con k = 5\n",
      "F1 Score Test1:  0.988315122292647\n",
      "F1 Score Test2:  0.9700495212941566\n",
      "Accuracy Test1:  0.9774420568640331\n",
      "Accuracy Test2:  0.9422268639987773\n"
     ]
    }
   ],
   "source": [
    "#Entrenando con k = 5\n",
    "knn_temp = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_temp.fit(X, y)\n",
    "#Calculando métricas\n",
    "f1_test1 = f1_score(y_testing_1, knn_temp.predict(X_testing_1))\n",
    "f1_test2 = f1_score(y_testing_2, knn_temp.predict(X_testing_2))\n",
    "accuracy_test1 = accuracy_score(y_testing_1, knn_temp.predict(X_testing_1), average='macro')\n",
    "accuracy_test2 = accuracy_score(y_testing_2, knn_temp.predict(X_testing_2), average='macro')\n",
    "#Imprimiendo resultados\n",
    "print(\"Resultaods con k = 5\")\n",
    "print(\"F1 Score Test1: \", f1_test1)\n",
    "print(\"F1 Score Test2: \", f1_test2)\n",
    "print(\"Accuracy Test1: \", accuracy_test1)\n",
    "print(\"Accuracy Test2: \", accuracy_test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando hiperparámetros para KNN con df Training balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=   7.0s\n",
      "[CV] END ....................n_neighbors=1, weights=distance; total time=   7.0s\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=   7.1s\n",
      "[CV] END ....................n_neighbors=3, weights=distance; total time=   7.1s\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=   7.1s\n",
      "[CV] END ....................n_neighbors=1, weights=distance; total time=   7.2s\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=   7.2s\n",
      "[CV] END ....................n_neighbors=10, weights=uniform; total time=   7.2s\n",
      "[CV] END ....................n_neighbors=1, weights=distance; total time=   7.0s\n",
      "[CV] END .....................n_neighbors=1, weights=uniform; total time=   6.9s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=   7.2s\n",
      "[CV] END .....................n_neighbors=1, weights=uniform; total time=   7.1s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=   7.2s\n",
      "[CV] END .....................n_neighbors=6, weights=uniform; total time=   7.2s\n",
      "[CV] END ....................n_neighbors=12, weights=uniform; total time=   7.2s\n",
      "[CV] END .....................n_neighbors=1, weights=uniform; total time=   9.6s\n",
      "[CV] END ....................n_neighbors=12, weights=uniform; total time=   7.6s\n",
      "[CV] END ....................n_neighbors=12, weights=uniform; total time=   7.6s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=   7.4s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=   7.2s\n",
      "[CV] END ...................n_neighbors=10, weights=distance; total time=  10.0s\n",
      "[CV] END ...................n_neighbors=10, weights=distance; total time=  10.9s\n",
      "[CV] END ....................n_neighbors=6, weights=distance; total time=  10.8s\n",
      "[CV] END ...................n_neighbors=10, weights=distance; total time=  11.1s\n",
      "[CV] END .....................n_neighbors=2, weights=uniform; total time=   6.4s\n",
      "[CV] END .....................n_neighbors=2, weights=uniform; total time=   6.6s\n",
      "[CV] END .....................n_neighbors=2, weights=uniform; total time=   6.5s\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=   5.8s\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=   5.8s\n",
      "[CV] END ...................n_neighbors=18, weights=distance; total time=   5.6s\n"
     ]
    }
   ],
   "source": [
    "#Ajustando para training undersampled\n",
    "with mlflow.start_run(run_name=\"KNN-Training-Undersampled\"):\n",
    "    knn2 = grid_search.fit(X_us, y_us)\n",
    "    #Mejor modelo\n",
    "    best_model = knn2.best_estimator_\n",
    "    #Guardando resultados\n",
    "    mlflow.log_params(knn2.best_params_)\n",
    "    mlflow.log_metrics({\"best_score\":knn2.best_score_})\n",
    "    mlflow.sklearn.log_model(best_model,\"best_model\")\n",
    "    mlflow.sklearn.log_model(knn2, \"RandomizedSearchCV\")\n",
    "    #Guardando diccionario de resultados\n",
    "    results = knn2.cv_results_\n",
    "    results = pd.DataFrame(results)\n",
    "    with tempfile.NamedTemporaryFile(mode = \"w+\", suffix = \".parquet\", delete= False) as temp:\n",
    "        results.to_parquet(temp.name)\n",
    "        mlflow.log_artifact(temp.name,\"results/results.parquet\")\n",
    "        temp_path = temp.name\n",
    "    #Almacenando métricas con conjunto de datos\n",
    "    f1_test1 = f1_score(y_testing_1, knn2.predict(X_testing_1), average='macro')\n",
    "    f1_test2 = f1_score(y_testing_2, knn2.predict(X_testing_2), average='macro')\n",
    "    accuracy_test1 = accuracy_score(y_testing_1, knn2.predict(X_testing_1))\n",
    "    accuracy_test2 = accuracy_score(y_testing_2, knn2.predict(X_testing_2))\n",
    "    mlflow.log_metrics({\"f1_test1\":f1_test1, \"f1_test2\":f1_test2, \"accuracy_test1\":accuracy_test1, \"accuracy_test2\":accuracy_test2})\n",
    "    os.remove(temp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
