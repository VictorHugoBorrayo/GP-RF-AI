{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando librearias\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from Resources.mlTracker import *\n",
    "from Python.Style.styles import  *\n",
    "from scipy.stats import uniform, randint\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desactivando wrnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/training_shuffled.parquet\")\n",
    "training_us = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/undersampled_shuffled.parquet\")\n",
    "training_os = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/oversampled_shuffled.parquet\")\n",
    "testing1 = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/testing1.parquet\")\n",
    "testing2 = pd.read_parquet(\"../../Data/DataMart/Views/TrainingViews/testing2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To delete columns\n",
    "total_columns = training.columns\n",
    "tdc = ['serialNumber','serialNumber_neighbor','fixed_path','FE-Comments','Conjunto','PSNumber']\n",
    "training_cols = list(filter(lambda x: x not in tdc, total_columns))\n",
    "#Seleccionando columnas\n",
    "training = training[training_cols]\n",
    "training_us = training_us[training_cols]\n",
    "training_os = training_os[training_cols]\n",
    "testing1 = testing1[training_cols]\n",
    "testing2 = testing2[training_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando etiquetas\n",
    "#Training\n",
    "y = training['Communicating']\n",
    "X = training.drop('Communicating', axis=1)\n",
    "#Training undersampled\n",
    "y_us = training_us['Communicating']\n",
    "X_us = training_us.drop('Communicating', axis=1)\n",
    "#Training oversampled\n",
    "y_os = training_os['Communicating']\n",
    "X_os = training_os.drop('Communicating', axis=1)\n",
    "#Test1\n",
    "y_testing_1 = testing1['Communicating']\n",
    "X_testing_1 = testing1.drop('Communicating', axis=1)\n",
    "#Test2\n",
    "y_testing_2 = testing2['Communicating']\n",
    "X_testing_2 = testing2.drop('Communicating', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seteando experimento\n",
    "experiment_name = \"ML\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros de búsqueda\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 500),  #Número de árboles\n",
    "    'max_depth': randint(3, 10),  #Profundidad máxima de cada árbol\n",
    "    'learning_rate': uniform(0.01, 0.3),  #Tasa de aprendizaje\n",
    "    'subsample': uniform(0.7, 0.3),  #Fracción de datos a usar\n",
    "    'min_samples_split': randint(2, 20),  #Número mínimo de muestras para dividir un nodo\n",
    "    'min_samples_leaf': randint(1, 20)  #Número mínimo de muestras en una hoja\n",
    "}\n",
    "#Métricas de interés\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo y GridSearchCV\n",
    "gb_model = GradientBoostingClassifier()\n",
    "randomized_search = RandomizedSearchCV(\n",
    "                            estimator= gb_model,\n",
    "                            param_distributions= param_dist,\n",
    "                            n_iter= 10,\n",
    "                            cv= 3,\n",
    "                            scoring= scoring,\n",
    "                            refit= 'F1',\n",
    "                            return_train_score= False,\n",
    "                            n_jobs= 4,\n",
    "                            verbose= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando hiperparámetros para Gradient Boosting Classifier con conjunto de datos con submuestreo de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 1/3] END learning_rate=0.03818087739594792, max_depth=9, min_samples_leaf=10, min_samples_split=9, n_estimators=259, subsample=0.8093923083779435; Accuracy: (test=0.984) F1: (test=0.984) total time= 4.1min\n",
      "[CV 2/3] END learning_rate=0.23598549696520182, max_depth=6, min_samples_leaf=11, min_samples_split=17, n_estimators=489, subsample=0.7037728112408794; Accuracy: (test=0.991) F1: (test=0.991) total time= 4.7min\n",
      "[CV 1/3] END learning_rate=0.23598549696520182, max_depth=6, min_samples_leaf=11, min_samples_split=17, n_estimators=489, subsample=0.7037728112408794; Accuracy: (test=0.990) F1: (test=0.990) total time= 4.7min\n",
      "[CV 3/3] END learning_rate=0.23598549696520182, max_depth=6, min_samples_leaf=11, min_samples_split=17, n_estimators=489, subsample=0.7037728112408794; Accuracy: (test=0.991) F1: (test=0.991) total time= 4.7min\n",
      "[CV 2/3] END learning_rate=0.11532514955824168, max_depth=4, min_samples_leaf=6, min_samples_split=7, n_estimators=113, subsample=0.8892045041242936; Accuracy: (test=0.929) F1: (test=0.929) total time=  53.5s\n",
      "[CV 1/3] END learning_rate=0.11532514955824168, max_depth=4, min_samples_leaf=6, min_samples_split=7, n_estimators=113, subsample=0.8892045041242936; Accuracy: (test=0.924) F1: (test=0.924) total time=  53.7s\n",
      "[CV 3/3] END learning_rate=0.11532514955824168, max_depth=4, min_samples_leaf=6, min_samples_split=7, n_estimators=113, subsample=0.8892045041242936; Accuracy: (test=0.922) F1: (test=0.922) total time=  53.7s\n",
      "[CV 2/3] END learning_rate=0.03818087739594792, max_depth=9, min_samples_leaf=10, min_samples_split=9, n_estimators=259, subsample=0.8093923083779435; Accuracy: (test=0.987) F1: (test=0.987) total time= 4.0min\n",
      "[CV 1/3] END learning_rate=0.303524804440041, max_depth=3, min_samples_leaf=3, min_samples_split=17, n_estimators=458, subsample=0.9556501550163943; Accuracy: (test=0.980) F1: (test=0.980) total time= 2.9min\n",
      "[CV 3/3] END learning_rate=0.03818087739594792, max_depth=9, min_samples_leaf=10, min_samples_split=9, n_estimators=259, subsample=0.8093923083779435; Accuracy: (test=0.983) F1: (test=0.983) total time= 4.0min\n",
      "[CV 2/3] END learning_rate=0.303524804440041, max_depth=3, min_samples_leaf=3, min_samples_split=17, n_estimators=458, subsample=0.9556501550163943; Accuracy: (test=0.984) F1: (test=0.984) total time= 2.9min\n",
      "[CV 1/3] END learning_rate=0.2812392758234304, max_depth=8, min_samples_leaf=15, min_samples_split=7, n_estimators=83, subsample=0.7287208569285649; Accuracy: (test=0.988) F1: (test=0.988) total time= 1.1min\n",
      "[CV 2/3] END learning_rate=0.2812392758234304, max_depth=8, min_samples_leaf=15, min_samples_split=7, n_estimators=83, subsample=0.7287208569285649; Accuracy: (test=0.989) F1: (test=0.989) total time= 1.1min\n",
      "[CV 3/3] END learning_rate=0.2812392758234304, max_depth=8, min_samples_leaf=15, min_samples_split=7, n_estimators=83, subsample=0.7287208569285649; Accuracy: (test=0.988) F1: (test=0.988) total time= 1.1min\n",
      "[CV 3/3] END learning_rate=0.303524804440041, max_depth=3, min_samples_leaf=3, min_samples_split=17, n_estimators=458, subsample=0.9556501550163943; Accuracy: (test=0.982) F1: (test=0.982) total time= 2.9min\n",
      "[CV 1/3] END learning_rate=0.12768810876866787, max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=412, subsample=0.8613784976046415; Accuracy: (test=0.977) F1: (test=0.977) total time= 3.2min\n",
      "[CV 2/3] END learning_rate=0.12768810876866787, max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=412, subsample=0.8613784976046415; Accuracy: (test=0.980) F1: (test=0.980) total time= 3.2min\n",
      "[CV 3/3] END learning_rate=0.12768810876866787, max_depth=4, min_samples_leaf=4, min_samples_split=4, n_estimators=412, subsample=0.8613784976046415; Accuracy: (test=0.977) F1: (test=0.977) total time= 3.2min\n",
      "[CV 1/3] END learning_rate=0.05792639651189571, max_depth=6, min_samples_leaf=4, min_samples_split=8, n_estimators=249, subsample=0.9481205642811605; Accuracy: (test=0.973) F1: (test=0.973) total time= 3.1min\n",
      "[CV 1/3] END learning_rate=0.0643191720364837, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=134, subsample=0.9992118336483157; Accuracy: (test=0.926) F1: (test=0.926) total time= 1.5min\n",
      "[CV 2/3] END learning_rate=0.0643191720364837, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=134, subsample=0.9992118336483157; Accuracy: (test=0.935) F1: (test=0.935) total time= 1.4min\n",
      "[CV 2/3] END learning_rate=0.05792639651189571, max_depth=6, min_samples_leaf=4, min_samples_split=8, n_estimators=249, subsample=0.9481205642811605; Accuracy: (test=0.974) F1: (test=0.974) total time= 3.1min\n",
      "[CV 3/3] END learning_rate=0.05792639651189571, max_depth=6, min_samples_leaf=4, min_samples_split=8, n_estimators=249, subsample=0.9481205642811605; Accuracy: (test=0.970) F1: (test=0.970) total time= 3.1min\n",
      "[CV 3/3] END learning_rate=0.0643191720364837, max_depth=5, min_samples_leaf=4, min_samples_split=4, n_estimators=134, subsample=0.9992118336483157; Accuracy: (test=0.926) F1: (test=0.926) total time= 1.4min\n",
      "[CV 1/3] END learning_rate=0.11295093225557415, max_depth=4, min_samples_leaf=6, min_samples_split=15, n_estimators=276, subsample=0.7253154369274524; Accuracy: (test=0.968) F1: (test=0.968) total time= 1.8min\n",
      "[CV 2/3] END learning_rate=0.11295093225557415, max_depth=4, min_samples_leaf=6, min_samples_split=15, n_estimators=276, subsample=0.7253154369274524; Accuracy: (test=0.969) F1: (test=0.969) total time= 1.8min\n",
      "[CV 1/3] END learning_rate=0.28452307106496755, max_depth=8, min_samples_leaf=8, min_samples_split=7, n_estimators=396, subsample=0.7982965736031029; Accuracy: (test=0.991) F1: (test=0.991) total time= 5.5min\n",
      "[CV 2/3] END learning_rate=0.28452307106496755, max_depth=8, min_samples_leaf=8, min_samples_split=7, n_estimators=396, subsample=0.7982965736031029; Accuracy: (test=0.992) F1: (test=0.992) total time= 5.5min\n",
      "[CV 3/3] END learning_rate=0.28452307106496755, max_depth=8, min_samples_leaf=8, min_samples_split=7, n_estimators=396, subsample=0.7982965736031029; Accuracy: (test=0.991) F1: (test=0.991) total time= 5.5min\n",
      "[CV 3/3] END learning_rate=0.11295093225557415, max_depth=4, min_samples_leaf=6, min_samples_split=15, n_estimators=276, subsample=0.7253154369274524; Accuracy: (test=0.963) F1: (test=0.963) total time= 1.8min\n"
     ]
    }
   ],
   "source": [
    "#Ajustando para training\n",
    "with mlflow.start_run(run_name=\"gbc_training_undersampled\"):\n",
    "    mlflow.log_param(\"model\",\"GradientBoostingClassifier\")\n",
    "    mlflow.log_param(\"data\",\"training_undersampled\")\n",
    "    #Almacenando información de param_dist\n",
    "    mlflow.log_param(\"dist_n_estimators\",\"randint(50, 500)\")\n",
    "    mlflow.log_param(\"dist_max_depth\",\"randint(3, 10)\")\n",
    "    mlflow.log_param(\"dist_learning_rate\",\"uniform(0.01, 0.3)\")\n",
    "    mlflow.log_param(\"dist_subsample\",\"uniform(0.7, 0.3)\")\n",
    "    mlflow.log_param(\"dist_min_samples_split\",\"randint(2, 20)\")\n",
    "    mlflow.log_param(\"dist_min_samples_leaf\",\"randint(1, 20)\")\n",
    "    #Entrenando modelo\n",
    "    gbc1 = randomized_search.fit(X_us, y_us)\n",
    "    #Mejor modelo\n",
    "    best_model = gbc1.best_estimator_\n",
    "    #Guardando resultados\n",
    "    mlflow.log_params(gbc1.best_params_)\n",
    "    mlflow.log_metrics({\"best_score\":gbc1.best_score_})\n",
    "    mlflow.sklearn.log_model(best_model,\"best_model\")\n",
    "    mlflow.sklearn.log_model(gbc1, \"RandomizedSearchCV\")\n",
    "    #Guardando diccionario de resultados\n",
    "    results = gbc1.cv_results_\n",
    "    results = pd.DataFrame(results)\n",
    "    with tempfile.NamedTemporaryFile(mode = \"w+\", suffix = \".parquet\", delete= False) as temp:\n",
    "        results.to_parquet(temp.name)\n",
    "        mlflow.log_artifact(temp.name,\"results/results.parquet\")\n",
    "        temp_path = temp.name\n",
    "    #Almacenando métricas con conjunto de datos\n",
    "    f1_test1 = f1_score(y_testing_1, gbc1.predict(X_testing_1), average='macro')\n",
    "    f1_test2 = f1_score(y_testing_2, gbc1.predict(X_testing_2), average='macro')\n",
    "    accuracy_test1 = accuracy_score(y_testing_1, gbc1.predict(X_testing_1))\n",
    "    accuracy_test2 = accuracy_score(y_testing_2, gbc1.predict(X_testing_2))\n",
    "    mlflow.log_metrics({\"f1_test1\":f1_test1, \"f1_test2\":f1_test2, \"accuracy_test1\":accuracy_test1, \"accuracy_test2\":accuracy_test2})\n",
    "    os.remove(temp_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando hiperparámetros para Support Vector Machine con conjunto de datos con sobremuestreo de la clase minoritaria - exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo y GridSearchCV\n",
    "gb_model = GradientBoostingClassifier()\n",
    "randomized_search_2 = RandomizedSearchCV(\n",
    "                            estimator= gb_model,\n",
    "                            param_distributions= param_dist,\n",
    "                            n_iter= 5,\n",
    "                            cv= 3,\n",
    "                            scoring= scoring,\n",
    "                            refit= 'F1',\n",
    "                            return_train_score= False,\n",
    "                            n_jobs= 4,\n",
    "                            verbose= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3] END learning_rate=0.11293338338643794, max_depth=6, min_samples_leaf=13, min_samples_split=19, n_estimators=84, subsample=0.7812698247892147; Accuracy: (test=0.965) F1: (test=0.965) total time=20.1min\n",
      "[CV 2/3] END learning_rate=0.11293338338643794, max_depth=6, min_samples_leaf=13, min_samples_split=19, n_estimators=84, subsample=0.7812698247892147; Accuracy: (test=0.967) F1: (test=0.967) total time=20.1min\n",
      "[CV 3/3] END learning_rate=0.11293338338643794, max_depth=6, min_samples_leaf=13, min_samples_split=19, n_estimators=84, subsample=0.7812698247892147; Accuracy: (test=0.965) F1: (test=0.965) total time=20.1min\n",
      "[CV 1/3] END learning_rate=0.07853035947338263, max_depth=4, min_samples_leaf=10, min_samples_split=14, n_estimators=167, subsample=0.9209126637387717; Accuracy: (test=0.932) F1: (test=0.932) total time=29.7min\n",
      "[CV 3/3] END learning_rate=0.07853035947338263, max_depth=4, min_samples_leaf=10, min_samples_split=14, n_estimators=167, subsample=0.9209126637387717; Accuracy: (test=0.930) F1: (test=0.930) total time=27.5min\n",
      "[CV 2/3] END learning_rate=0.07853035947338263, max_depth=4, min_samples_leaf=10, min_samples_split=14, n_estimators=167, subsample=0.9209126637387717; Accuracy: (test=0.932) F1: (test=0.932) total time=27.5min\n",
      "[CV 1/3] END learning_rate=0.2887285934926241, max_depth=5, min_samples_leaf=7, min_samples_split=9, n_estimators=247, subsample=0.8224227048994814; Accuracy: (test=0.997) F1: (test=0.997) total time=46.0min\n",
      "[CV 2/3] END learning_rate=0.2887285934926241, max_depth=5, min_samples_leaf=7, min_samples_split=9, n_estimators=247, subsample=0.8224227048994814; Accuracy: (test=0.997) F1: (test=0.997) total time=45.9min\n",
      "[CV 1/3] END learning_rate=0.158074690608621, max_depth=4, min_samples_leaf=12, min_samples_split=5, n_estimators=251, subsample=0.9097263626475562; Accuracy: (test=0.977) F1: (test=0.977) total time=41.0min\n",
      "[CV 3/3] END learning_rate=0.2887285934926241, max_depth=5, min_samples_leaf=7, min_samples_split=9, n_estimators=247, subsample=0.8224227048994814; Accuracy: (test=0.997) F1: (test=0.997) total time=46.2min\n",
      "[CV 1/3] END learning_rate=0.06729507576174236, max_depth=3, min_samples_leaf=4, min_samples_split=17, n_estimators=58, subsample=0.8393048631808576; Accuracy: (test=0.816) F1: (test=0.815) total time= 7.0min\n",
      "[CV 2/3] END learning_rate=0.06729507576174236, max_depth=3, min_samples_leaf=4, min_samples_split=17, n_estimators=58, subsample=0.8393048631808576; Accuracy: (test=0.818) F1: (test=0.818) total time= 7.1min\n",
      "[CV 3/3] END learning_rate=0.06729507576174236, max_depth=3, min_samples_leaf=4, min_samples_split=17, n_estimators=58, subsample=0.8393048631808576; Accuracy: (test=0.814) F1: (test=0.814) total time= 7.1min\n",
      "[CV 2/3] END learning_rate=0.158074690608621, max_depth=4, min_samples_leaf=12, min_samples_split=5, n_estimators=251, subsample=0.9097263626475562; Accuracy: (test=0.979) F1: (test=0.979) total time=41.0min\n",
      "[CV 3/3] END learning_rate=0.158074690608621, max_depth=4, min_samples_leaf=12, min_samples_split=5, n_estimators=251, subsample=0.9097263626475562; Accuracy: (test=0.977) F1: (test=0.977) total time=40.5min\n"
     ]
    }
   ],
   "source": [
    "#Ajustando para training\n",
    "with mlflow.start_run(run_name=\"gbc_training_oversampled\"):\n",
    "    mlflow.log_param(\"model\",\"GradientBoostingClassifier\")\n",
    "    mlflow.log_param(\"data\",\"training_oversampled\")\n",
    "    #Almacenando información de param_dist\n",
    "    mlflow.log_param(\"dist_n_estimators\",\"randint(50, 500)\")\n",
    "    mlflow.log_param(\"dist_max_depth\",\"randint(3, 10)\")\n",
    "    mlflow.log_param(\"dist_learning_rate\",\"uniform(0.01, 0.3)\")\n",
    "    mlflow.log_param(\"dist_subsample\",\"uniform(0.7, 0.3)\")\n",
    "    mlflow.log_param(\"dist_min_samples_split\",\"randint(2, 20)\")\n",
    "    mlflow.log_param(\"dist_min_samples_leaf\",\"randint(1, 20)\")\n",
    "    mlflow.log_param(\"dist_n_iter\",5)\n",
    "    #Entrenando modelo\n",
    "    gbc2 = randomized_search_2.fit(X_os, y_os)\n",
    "    #Mejor modelo\n",
    "    best_model = gbc2.best_estimator_\n",
    "    #Guardando resultados\n",
    "    mlflow.log_params(gbc2.best_params_)\n",
    "    mlflow.log_metrics({\"best_score\":gbc2.best_score_})\n",
    "    mlflow.sklearn.log_model(best_model,\"best_model\")\n",
    "    mlflow.sklearn.log_model(gbc2, \"RandomizedSearchCV\")\n",
    "    #Guardando diccionario de resultados\n",
    "    results = gbc2.cv_results_\n",
    "    results = pd.DataFrame(results)\n",
    "    with tempfile.NamedTemporaryFile(mode = \"w+\", suffix = \".parquet\", delete= False) as temp:\n",
    "        try:\n",
    "            results.to_parquet(temp.name)\n",
    "        except:\n",
    "            results = results.astype(str)\n",
    "        mlflow.log_artifact(temp.name,\"results/results.parquet\")\n",
    "        temp_path = temp.name\n",
    "    #Almacenando métricas con conjunto de datos\n",
    "    f1_test1 = f1_score(y_testing_1, gbc2.predict(X_testing_1), average='macro')\n",
    "    f1_test2 = f1_score(y_testing_2, gbc2.predict(X_testing_2), average='macro')\n",
    "    accuracy_test1 = accuracy_score(y_testing_1, gbc2.predict(X_testing_1))\n",
    "    accuracy_test2 = accuracy_score(y_testing_2, gbc2.predict(X_testing_2))\n",
    "    mlflow.log_metrics({\"f1_test1\":f1_test1, \"f1_test2\":f1_test2, \"accuracy_test1\":accuracy_test1, \"accuracy_test2\":accuracy_test2})\n",
    "    os.remove(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error anterior es independiente del entrenamiento, fue causado debido a los tipos de datos en una columna particular. Por tal motivo se almacenará en el run que fue interrumpido, sin volver a entrenar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = get_run_id(experiment_name, \"RF-Training\")\n",
    "#Guardando resultados pendientes\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    #Guardando df con\n",
    "    results = rf1.cv_results_\n",
    "    results = pd.DataFrame(results)\n",
    "    with tempfile.NamedTemporaryFile(mode = \"w+\", suffix = \".parquet\", delete= False) as temp:\n",
    "        try:\n",
    "            results.to_parquet(temp.name)\n",
    "        except:\n",
    "            results = results.astype(str)\n",
    "        mlflow.log_artifact(temp.name,\"results/results.parquet\")\n",
    "        temp_path = temp.name\n",
    "    #Almacenando métricas con conjunto de datos\n",
    "    f1_test1 = f1_score(y_testing_1, rf1.predict(X_testing_1), average='macro')\n",
    "    f1_test2 = f1_score(y_testing_2, rf1.predict(X_testing_2), average='macro')\n",
    "    accuracy_test1 = accuracy_score(y_testing_1, rf1.predict(X_testing_1))\n",
    "    accuracy_test2 = accuracy_score(y_testing_2, rf1.predict(X_testing_2))\n",
    "    mlflow.log_metrics({\"f1_test1\":f1_test1, \"f1_test2\":f1_test2, \"accuracy_test1\":accuracy_test1, \"accuracy_test2\":accuracy_test2})\n",
    "    os.remove(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando hiperparámetros para Random Forest con df Training balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=True, criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=200; Accuracy: (test=0.801) F1: (test=0.801) total time=  10.9s\n",
      "[CV 2/3] END bootstrap=True, criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=200; Accuracy: (test=0.798) F1: (test=0.798) total time=  10.4s\n",
      "[CV 3/3] END bootstrap=True, criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=200; Accuracy: (test=0.794) F1: (test=0.793) total time=  10.5s\n",
      "[CV 1/3] END bootstrap=True, criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; Accuracy: (test=0.973) F1: (test=0.973) total time=  10.8s\n",
      "[CV 1/3] END bootstrap=False, criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; Accuracy: (test=0.981) F1: (test=0.981) total time=  46.3s\n",
      "[CV 2/3] END bootstrap=False, criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; Accuracy: (test=0.982) F1: (test=0.982) total time=  47.8s\n",
      "[CV 3/3] END bootstrap=False, criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; Accuracy: (test=0.981) F1: (test=0.981) total time=  48.0s\n",
      "[CV 2/3] END bootstrap=True, criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; Accuracy: (test=0.976) F1: (test=0.976) total time=  10.6s\n",
      "[CV 3/3] END bootstrap=True, criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; Accuracy: (test=0.972) F1: (test=0.972) total time=  10.6s\n",
      "[CV 2/3] END bootstrap=True, criterion=gini, max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; Accuracy: (test=0.982) F1: (test=0.982) total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, criterion=gini, max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; Accuracy: (test=0.980) F1: (test=0.980) total time= 1.3min\n",
      "[CV 3/3] END bootstrap=True, criterion=gini, max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=200; Accuracy: (test=0.980) F1: (test=0.980) total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, criterion=entropy, max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=0.01, n_estimators=100; Accuracy: (test=0.913) F1: (test=0.913) total time=  43.6s\n",
      "[CV 2/3] END bootstrap=False, criterion=entropy, max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=0.01, n_estimators=100; Accuracy: (test=0.916) F1: (test=0.916) total time=  42.7s\n",
      "[CV 3/3] END bootstrap=False, criterion=entropy, max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=0.01, n_estimators=100; Accuracy: (test=0.907) F1: (test=0.907) total time=  42.9s\n",
      "[CV 1/3] END bootstrap=False, criterion=entropy, max_depth=40, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=400; Accuracy: (test=0.983) F1: (test=0.983) total time= 3.5min\n",
      "[CV 2/3] END bootstrap=False, criterion=entropy, max_depth=40, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=400; Accuracy: (test=0.985) F1: (test=0.985) total time= 3.4min\n",
      "[CV 3/3] END bootstrap=False, criterion=entropy, max_depth=40, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=400; Accuracy: (test=0.985) F1: (test=0.985) total time= 3.5min\n",
      "[CV 1/3] END bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=0.01, n_estimators=200; Accuracy: (test=0.885) F1: (test=0.885) total time=  17.0s\n",
      "[CV 2/3] END bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=0.01, n_estimators=200; Accuracy: (test=0.879) F1: (test=0.879) total time=  16.8s\n",
      "[CV 3/3] END bootstrap=True, criterion=entropy, max_depth=40, max_features=sqrt, min_samples_leaf=2, min_samples_split=0.01, n_estimators=200; Accuracy: (test=0.877) F1: (test=0.877) total time=  17.0s\n",
      "[CV 1/3] END bootstrap=True, criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; Accuracy: (test=0.976) F1: (test=0.976) total time=  35.0s\n",
      "[CV 2/3] END bootstrap=True, criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; Accuracy: (test=0.978) F1: (test=0.978) total time=  35.3s\n",
      "[CV 3/3] END bootstrap=True, criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; Accuracy: (test=0.976) F1: (test=0.976) total time=  35.6s\n",
      "[CV 1/3] END bootstrap=True, criterion=gini, max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; Accuracy: (test=0.978) F1: (test=0.978) total time=  38.4s\n",
      "[CV 2/3] END bootstrap=True, criterion=gini, max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; Accuracy: (test=0.980) F1: (test=0.980) total time=  38.4s\n",
      "[CV 3/3] END bootstrap=True, criterion=gini, max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=100; Accuracy: (test=0.977) F1: (test=0.977) total time=  38.7s\n",
      "[CV 1/3] END bootstrap=False, criterion=entropy, max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=0.01, n_estimators=1000; Accuracy: (test=0.877) F1: (test=0.877) total time= 6.0min\n",
      "[CV 2/3] END bootstrap=False, criterion=entropy, max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=0.01, n_estimators=1000; Accuracy: (test=0.880) F1: (test=0.880) total time= 6.0min\n",
      "[CV 3/3] END bootstrap=False, criterion=entropy, max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=0.01, n_estimators=1000; Accuracy: (test=0.875) F1: (test=0.875) total time= 6.0min\n"
     ]
    }
   ],
   "source": [
    "#Ajustando para training undersampled\n",
    "with mlflow.start_run(run_name=\"RF-Training-Undersampled\"):\n",
    "    rf2 = randomized_search.fit(X_us, y_us)\n",
    "    #Mejor modelo\n",
    "    best_model = rf2.best_estimator_\n",
    "    #Guardando resultados\n",
    "    mlflow.log_params(rf2.best_params_)\n",
    "    mlflow.log_metrics({\"best_score\":rf2.best_score_})\n",
    "    mlflow.sklearn.log_model(best_model,\"best_model\")\n",
    "    mlflow.sklearn.log_model(rf2, \"RandomizedSearchCV\")\n",
    "    #Guardando diccionario de resultados\n",
    "    results = rf2.cv_results_\n",
    "    results = pd.DataFrame(results)\n",
    "    with tempfile.NamedTemporaryFile(mode = \"w+\", suffix = \".parquet\", delete= False) as temp:\n",
    "        try:\n",
    "            results.to_parquet(temp.name)\n",
    "        except:\n",
    "            results = results.astype(str)\n",
    "        mlflow.log_artifact(temp.name,\"results/results.parquet\")\n",
    "        temp_path = temp.name\n",
    "    #Almacenando métricas con conjunto de datos\n",
    "    f1_test1 = f1_score(y_testing_1, rf2.predict(X_testing_1), average='macro')\n",
    "    f1_test2 = f1_score(y_testing_2, rf2.predict(X_testing_2), average='macro')\n",
    "    accuracy_test1 = accuracy_score(y_testing_1, rf2.predict(X_testing_1))\n",
    "    accuracy_test2 = accuracy_score(y_testing_2, rf2.predict(X_testing_2))\n",
    "    mlflow.log_metrics({\"f1_test1\":f1_test1, \"f1_test2\":f1_test2, \"accuracy_test1\":accuracy_test1, \"accuracy_test2\":accuracy_test2})\n",
    "    os.remove(temp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
